shared:
  image_size: &image_size 512
  batch_size: &batch_size 3
  num_workers: &num_workers 12
  learning_rate: &learning_rate 2e-4
  learning_rate_2: &learning_rate_2 4e-5
  weight_decay: &weight_decay 1e-6

  # {SPECIFY} Style image
  image_style_path: &image_style_path styles/style_city.jpg

  # {SPECIFY} where to get features for style [1 .. 8] for 256x256 image is enough
  style_block_indices: &style_block_indices [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
  # {SPECIFY} where to gen content features 3-4 for save small details, 8-9 for only main contours
  content_block_indices: &content_block_indices [7]
  # {SPECIFY} max(max(style_block_indices), max(content_block_indices))
  num_hidden_relu: &num_hidden_relu 14


  # {SPECIFY} trade-off between style and content
  style_weight: &style_weight 1000000
  content_weight: &content_weight 25

  total_variation_weight: &total_variation_weight 1e-4

  # {SPECIFY} directory with real-world images from the same domain with inference images
  src_images_path: &src_image_path /datasets/mscoco/unlabeled2017

model_params:
  model: ImageTransformer
  num_hidden_relu: *num_hidden_relu

args:
  expdir: src
  logdir: logs
  seed: 42
  deterministic: False
  verbose: True

runner_params:
  input_key: src_image
  output_key: null

stages:
  state_params:
    main_metric: agg_loss
    minimize_metric: True
    valid_loader: train

  data_params:
    num_workers: *num_workers
    batch_size: *batch_size
    image_size: *image_size
    path: *src_image_path

    sampler_params:
      drop_last: True
      shuffle: per_epoch

  criterion_params:
    _key_value: True
    style_loss:
      criterion: StyleLoss
      style_filename: *image_style_path
      num_hidden_relu: *num_hidden_relu
      image_size: *image_size
      block_indices: *style_block_indices
    content_loss:
      criterion: ContentLoss
      block_indices: *content_block_indices
    total_variation_loss:
      criterion: TotalVariationLoss

  scheduler_params:
    scheduler: MultiStepLR
    milestones: [12, 40]
    gamma: 0.1

  callbacks_params:
    optimizer:
      callback: OptimizerCallback
      grad_clip_params:
        func: clip_grad_value_
        clip_value: 5.0
      metric_key: agg_loss

    loss_tv:
      callback: CriterionCallback
      input_key: {}
      output_key:
        generated_image: output_tensor
      prefix: loss_tv
      criterion_key: total_variation_loss
      multiplier: *total_variation_weight

    loss_style:
      callback: CriterionCallback
      input_key: {}
      output_key:
        vgg_generated_features: vgg_predictions
      prefix: loss_style
      criterion_key: style_loss
      multiplier: *style_weight

    loss_content:
      callback: CriterionCallback
      input_key: {}
      output_key:
        vgg_origin_features: target_predictions
        vgg_generated_features: result_predictions

      prefix: loss_content
      criterion_key: content_loss
      multiplier: *content_weight

    loss_aggregator:
      callback: MetricAggregationCallback
      prefix: agg_loss
      metrics: ["loss_tv", "loss_content", "loss_style"]
      mode: "sum"

    scheduler:
      callback: SchedulerCallback
      reduced_metric: agg_loss

    saver:
      callback: CheckpointCallback
      save_n_best: 10

  stage1:
    state_params:
      num_epochs: 3

    optimizer_params:
      optimizer: Lookahead
      base_optimizer_params:
        optimizer: RAdam
        lr: *learning_rate
        weight_decay: *weight_decay
      no_bias_weight_decay: True

  stage2:
    state_params:
      num_epochs: 4

    optimizer_params:
      optimizer: Lookahead
      base_optimizer_params:
        optimizer: RAdam
        lr: *learning_rate_2
        weight_decay: *weight_decay
      no_bias_weight_decay: True